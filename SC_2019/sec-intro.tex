

\section{Introduction}
\label{sec:intro}
%
Implementing application-specific code on supercomputers requires addressing the fundamental underlying primitives of an algorithm in a way that is flexible and scalable. Significant progress has been made on a wide variety of important problems due to a rigorous exploration of common high-performance primitives such as stencil computations, floating-point arithmetic, numerical integration, and sparse linear algebra. 

Relational algebra is a crucial primitive for a wide range of analytic problems in graphs, machine learning, logic programming, program analysis, deductive databases, and formal verification, that has been the subject of great interest in the literature, but has had limited exploration on supercomputers, and at scale. Two central barriers to scaling operations on relations, such as union, selection, projection, and join, have been (a) how to represent distributed relations in a way that is amenable to efficient parallel operations, and (b) how to handle communication to coordinate distinct portions of the distributed workload.

While some recent progress has been made in addressing these issues, (a) in particular, no approach has yet provided a general framework that makes applications using a pipeline of \emph{repeated} operations on relations---for fixed-point interation, supporting applications such as Datalog and program analysis---possible at scale. For such applications to be implemented on distributed, many-core systems, existing algorithms that distribute relations among available cores, perform a single operation, and return in map-reduce fashion are not suitable as repeated operations require efficient granular communication at each step. 

In this paper, we present a hybrid approach to representing relations on networked machines and performing efficient distributed operations on them, building on the current state of the art for single-node parallelism. Interestingly, in addressing the communication issue, we find that MPI's all-to-all communication paradigm suits relational algebra best. Today's supercomputers have specialized, high speed interconnects and data can be transmitted between processes with very low latency. When used with an appropriate configuration, all-to-all communication---known to be the most intensive mode of communication---can scale well.


\paragraph{Contributions} In particular, we make the following specific contributions to the literature:
\begin{tightenumerate}
	\item We present novel hybrid hash-tree based algorithms for distributed relational algebra.
	\item We present a scalable implemetation and experiments for a fixed-point algorithm employing distributed relational algebra: computing the transitive closure of a graph.
	\item We demonstrate scalability of transitive closure up to $65,\!536$ processes, producing a graph with more than 276 billion edges. To the best of our knowledge, this is the largest transitive closure operation discussed in the literature. 
\end{tightenumerate}

We understand our implementation to be the first truly scalable distributed relational algebra that addresses inter-process communication, permitting fixed-point interation, and laying the foundation for solving massive logical inference problems, graph problems, and more, on supercomputers.





